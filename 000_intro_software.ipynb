{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Software Installation\n",
    "\n",
    "If this is your first time using a Jupyter notebook, please make sure to follow along with me in the class Video.  If you know what you are doing, just go ahead and run the cells and make sure everything works on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  No errors yet? Your software is installed!\n",
    "If you don't have any errors from running the cell above, then you are set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "Numpy stands for numerical python.  It's giving us a LOT of very special things.\n",
    "  * linear algebra\n",
    "  * runs in C (so it's fast)\n",
    "  * uses special libraries for your CPU to do the linear algebra routines FAST\n",
    "  * gives us ndarrays -- n-dimensional arrays.\n",
    "  \n",
    "Numpy is the basis of machine learning in python.  Without it -- you have nothing. Literally nothing.  Every tool we use will use numpy, keras, tensorflow, pytorch, pymc3, pandas, scikit-learn, scikit-image, every single machine learning library you will ever find in python stands on top of numpy.\n",
    "\n",
    "So let's see a tiny bit of what it can do\n",
    "\n",
    "Examples taken from:\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape, Ndmin\n",
    "\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimensional array\n",
    "x2 = np.random.randint(10, size=(3, 4))  # Two-dimensional array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5))  # Three-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x3 ndim: \", x3.ndim)\n",
    "print(\"x3 shape:\", x3.shape)\n",
    "print(\"x3 size: \", x3.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dtype:\", x3.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = np.arange(1,10)\n",
    "print(f\"The shape is {a.shape}\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "grid = np.arange(1, 10,.1).reshape((-1, 10))\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy uses vectorization\n",
    "\n",
    "Vectorization, uses Basic Linear Algebra Subroutines (BLAS), notably [strassens algorithm](https://youtu.be/ORrM-aSNZUs), and a bunch of other very cool things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reciprocals(values):\n",
    "    output = np.empty(len(values))\n",
    "    for i in range(len(values)):\n",
    "        output[i] = 1.0 / values[i]\n",
    "    return output\n",
    "\n",
    "\n",
    "values = np.random.randint(1, 10, size=5)\n",
    "print(values)\n",
    "print(compute_reciprocals(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.random.randint(1, 100, size=1000000)\n",
    "%timeit compute_reciprocals(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_reciprocals(values))\n",
    "print(1.0 / values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit (1.0 / big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "b = np.array([5, 5, 5])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.ones((3, 3))\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(3)\n",
    "b = np.arange(3)[:, np.newaxis]\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot a sine wave with numpy and matplotlib\n",
    "\n",
    "You can adjust the range of the wave by playing around with the `np.arange()` parameters, the syntax is `(start, stop, step)` just like normal python slicing.  Except with step we can step by decimal amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sin(np.arange(0,20,.1))\n",
    "x = np.arange(0,20,.1)\n",
    "\n",
    "# note in the video I may use plt.plot(x, a) -- this is will do the same as what I am using here, \n",
    "# BUT it is more confusing since it uses the stateful interface of matplotlib\n",
    "# instead of the object-oriented interface - we would like to ALWAYS use the object-oriented interface\n",
    "# for our mental sanity, it's the best way to use matplotlib.\n",
    "# if this is confusing, don't worry much about it now, we will cover it in detail later on!\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, a); # we add the semi-colon ; in order to suppress an object output from jupyter -- go ahead and try removing it, you will see!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can dress up our plot a bit with extra attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, a)\n",
    "ax.set_title(\"This is a Sine Wave\")\n",
    "ax.set_xlabel(\"These are the values of X\")\n",
    "ax.set_ylabel(\"Y LABEL!!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to control the size of the plot we have to do it _before_ we make the plot, at least that's one way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize allows us to control the size of the plot, and we access it through the plots figure object\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(x, a)\n",
    "ax.set_title(\"This is a Sine Wave\")\n",
    "ax.set_xlabel(\"These are the values of X\")\n",
    "ax.set_ylabel(\"Y LABEL!!\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally let's plot a few other things on the same plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.cos(np.arange(0,20,.1))\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(x, a, label = \"sine\", marker = 'o' ) # add a label so we can create a legend and mess with the marker\n",
    "ax.plot(x, b, label = 'cos', linewidth = 4, color = 'purple') # add b by simply plotting it as well. , make it thicker and purple\n",
    "ax.set_title(\"This is a Sine Wave AND a Cosine Wave\")\n",
    "ax.set_xlabel(\"These are the values of X\")\n",
    "ax.set_ylabel(\"Y LABEL!!\")\n",
    "ax.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, let's load up some data with Scikit-Learn and Pandas\n",
    "We will use some built-in datasets from Scikit-learn, later on we will learn to load our own data\n",
    "\n",
    "**Note:** In the video, I use the Boston housing dataset, that dataset is no longer distrubuted with scikit-learn, so I switched to the California housing dataset. Overall the California housing dataset is better and more interesting, so it's a good change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using a newer API than our video, we use as_frame=True, which \n",
    "# returns a DataFrame object as one of the attributes of the bunch object created.\n",
    "california = datasets.fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push our data into a pandas DataFrame for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the older way of doing this, when we didn't have the as_frame=True argument\n",
    "# so this is how I do it in the video\n",
    "housing = pd.DataFrame(california.data, columns = california.feature_names)\n",
    "\n",
    "\n",
    "## with as_frame=True you can just do\n",
    "housing = california.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shape of your data, presents as (rows , columns)\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 rows of the dataset\n",
    "housing.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 5 rows of data by default\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['AveRooms'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic stats on our numerical data\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Indexing\n",
    "\n",
    "Pandas has slicing built in, the same way python lists work (and numpy arrays).  This is done using the `[]` notation.  Additionally Pandas has some extra tricks with two main types of indexing `.iloc` which is primarily label based, and `.loc` which is primarily integer based.\n",
    "You can read more [at the official docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[:3]  # gives first 3 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[3:11:2]  #rows 3 through 11, stepping by 2, note the start in inclusive and the end is excluded (like python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.iloc`\n",
    "Ok, that works for rows, but as soon as we want columns in pandas we need to switch `.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.iloc[:3,:2] # the first 3 rows and 2 columns -- note the comma ',' which used to tell pandas that we are indexing both rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we can do the same things we did before with `.iloc` as well\n",
    "housing.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.loc`\n",
    "\n",
    "Here we will use the based indexing.  We can use it to select columns by their string name.  \n",
    "It's important to note that we will index with `.loc[:4, [strings]]` and that  4 is a label here, it's the index label, which happens to be an integer (it's an integer most of the time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.loc[:4, ['MedInc', 'HouseAge']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing\n",
    "\n",
    "So a common thing we may want to do is look for certain rows (or columns) that hold a certain value.  This can be done with boolean indexing easily with pandas.\n",
    "This is best thought of as a two step process\n",
    "(1) create a boolean _mask_ \n",
    "(2) use your mask to _index_ your dataframe.\n",
    "\n",
    "Let's answer the question \"Show me the rows where the age of the home is greater than 30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one, create the mask.\n",
    "mask = housing['HouseAge']>30\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can use my boolean mask to index on the dataframe.  This is obviously a bit more complicated under the hood -- but it works fabulously.\n",
    "housing[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will commonly see this pattern show up like this\n",
    "housing[housing['HouseAge']>30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A pandas Series is like a DataFrame, but for a single column\n",
    "\n",
    "All the same rules apply, plus there are a few neat inbuilt functions that are available only on Series, but they are mostly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_targets = pd.Series(california.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's load at some data we can \"look\" at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data[0].shape  # shape tells us the dimension of our data, it's a 1D vector with 64 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data[0].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits.data[0].reshape(8,8), cmap='gray')  #we reshaped it into an 8,8 in order to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape  #we have 1797 samples, each one is a vector of 64 rows.  In this case we have 1797 rows, each row is a row vector of length 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 10, figsize=(12, 2))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.data[i].reshape(8,8), cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
